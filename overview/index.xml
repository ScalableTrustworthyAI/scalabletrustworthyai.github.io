<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Overviews on Scalable Trustworthy AI</title><link>https://s-t-a-i.github.io/overview/</link><description>Recent content in Overviews on Scalable Trustworthy AI</description><generator>Hugo</generator><language>en</language><copyright>&amp;copy; Seong Joon Oh, 2024</copyright><atom:link href="https://s-t-a-i.github.io/overview/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://s-t-a-i.github.io/overview/overview/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://s-t-a-i.github.io/overview/overview/</guid><description>&lt;p&gt;AI is no longer a research curiosity. It is reshaping how we live and work. To fully exploit its benefits, we must address critical gaps in trustworthiness.&lt;/p&gt;
&lt;p&gt;Current foundational models like LLMs have critical trustworthiness problems: they hallucinate false information, fail at continual learning, resist knowledge editing (making GDPR compliance impractical), leak private information embedded in parameters, and require prohibitive compute for training and personalisation. These issues are blocking the widespread adoption of AI and the productivity revolution it promises.&lt;/p&gt;</description></item></channel></rss>