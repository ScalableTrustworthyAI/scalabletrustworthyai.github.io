<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Scalable Trustworthy AI</title><link>https://ScalableTrustworthyAI.github.io/</link><description>Recent content on Scalable Trustworthy AI</description><generator>Hugo</generator><language>en</language><copyright>&amp;copy; Seong Joon Oh, 2024</copyright><lastBuildDate>Mon, 01 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://ScalableTrustworthyAI.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Diffusion Classifiers Understand Compositionality, but Conditions Apply</title><link>https://ScalableTrustworthyAI.github.io/publication/yujin2025diffusion/</link><pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/yujin2025diffusion/</guid><description/></item><item><title>On the Rankability of Visual Embeddings</title><link>https://ScalableTrustworthyAI.github.io/publication/ankit2025ranking/</link><pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/ankit2025ranking/</guid><description/></item><item><title>Overcoming Domain Limitations in Open-vocabulary Segmentation</title><link>https://ScalableTrustworthyAI.github.io/publication/dongjun2025ovs/</link><pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/dongjun2025ovs/</guid><description/></item><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/bora/</link><pubDate>Fri, 09 May 2025 17:17:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/bora/</guid><description>&lt;p&gt;I am currently pursuing a Master’s degree in Machine Learning at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, where I am conducting my thesis research under the supervision of Seong Joon Oh and Arnas Uselis.&lt;/p&gt;
&lt;p&gt;My research interests lie in enhancing the generalization abilities of multimodal machine learning models and gaining deeper insight into when, why, and how they fail. I believe that studying model representations is key to understanding the underlying factors that drive model performance—both successes and failures.&lt;/p&gt;</description></item><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/philipp/</link><pubDate>Thu, 08 May 2025 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/philipp/</guid><description>&lt;p&gt;I am a MSc student at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, supervised by Seong Joon Oh, Elisa Nguyen, and Ameya Prabhu (Bethgelab Tübingen). My thesis aims to quantify the influence of training data samples on LLM-generated text. I am especially interested in how attribution results differ between base models and instruction-tuned models.&lt;/p&gt;
&lt;p&gt;I earned my Bachelor’s degree with distinction in &lt;a href="https://www.uni-goettingen.de/en/640713.html"&gt;Mathematical Data Science at the Georg-August University in Göttingen&lt;/a&gt;, where I wrote my thesis in cooperation with AUDI AG. There, I explored Active Learning to reduce labeling costs in Surface Defect Detection for Automobiles.&lt;/p&gt;</description></item><item><title>Does Data Scaling Lead to Visual Compositional Generalization?</title><link>https://ScalableTrustworthyAI.github.io/publication/arnas2025icml/</link><pubDate>Thu, 01 May 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/arnas2025icml/</guid><description/></item><item><title>Do Deep Neural Network Solutions Form a Star Domain?</title><link>https://ScalableTrustworthyAI.github.io/publication/ankit2024star/</link><pubDate>Thu, 03 Apr 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/ankit2024star/</guid><description/></item><item><title>Intermediate Layer Classifiers for OOD Generalization</title><link>https://ScalableTrustworthyAI.github.io/publication/arnas2025iclr/</link><pubDate>Thu, 03 Apr 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/arnas2025iclr/</guid><description/></item><item><title>Decoupled Finetuning for Domain Generalizable Semantic Segmentation</title><link>https://ScalableTrustworthyAI.github.io/publication/jaehyun2025iclr/</link><pubDate>Wed, 02 Apr 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/jaehyun2025iclr/</guid><description/></item><item><title>Are We Done with Object-Centric Learning?</title><link>https://ScalableTrustworthyAI.github.io/publication/alex2025ocl/</link><pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/alex2025ocl/</guid><description/></item><item><title>DiCoTTA: Domain-invariant Learning for Continual Test-time Adaptation</title><link>https://ScalableTrustworthyAI.github.io/publication/sohyun2025dicotta/</link><pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/sohyun2025dicotta/</guid><description/></item><item><title>Mitigating Shortcut Learning with Diffusion Counterfactuals and Diverse Ensembles</title><link>https://ScalableTrustworthyAI.github.io/publication/luca2025diffdiv/</link><pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/luca2025diffdiv/</guid><description/></item><item><title>Playing repeated games with Large Language Models</title><link>https://ScalableTrustworthyAI.github.io/publication/elif2025naturehumanbehaviour/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/elif2025naturehumanbehaviour/</guid><description/></item><item><title>CLIP Behaves like a Bag-of-Words Model Cross-modally but not Uni-modally</title><link>https://ScalableTrustworthyAI.github.io/publication/darina2025binding/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/darina2025binding/</guid><description/></item><item><title>Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks</title><link>https://ScalableTrustworthyAI.github.io/publication/balint2024disentanglement/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/balint2024disentanglement/</guid><description/></item><item><title>Studying Large Language Model Behaviors Under Realistic Knowledge Conflicts</title><link>https://ScalableTrustworthyAI.github.io/publication/evgenii2024ralm/</link><pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/evgenii2024ralm/</guid><description/></item><item><title>Towards User-Focused Research in Training Data Attribution for Human-Centered Explainable AI</title><link>https://ScalableTrustworthyAI.github.io/publication/elisa2024tda/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/elisa2024tda/</guid><description/></item><item><title>Scalable Ensemble Diversification for OOD Generalization and Detection</title><link>https://ScalableTrustworthyAI.github.io/publication/alex2024diversify/</link><pubDate>Wed, 25 Sep 2024 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/alex2024diversify/</guid><description/></item><item><title>Collaborating PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/lennart/</link><pubDate>Thu, 15 Aug 2024 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/lennart/</guid><description>&lt;p&gt;I am a PhD student, co-supervised by &lt;a href="https://cogsys.reutlingen-university.de/about-us/members/cristobal-curio/?L=1"&gt;Cristòbal Curio&lt;/a&gt; at Reutlingen University and &lt;a href="https://coallaoh.github.io/"&gt;Seong Joon Oh&lt;/a&gt; at the University of Tübingen. My personal page is at &lt;a href="https://lennartbramlage.com"&gt;lennartbramlage.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A broader interest in decision making under uncertainty has informed my current focus on rapid and accurate uncertainty estimation in deep neural networks. I believe that the quantification and source-attribution of their failures is indispensable wherever these models interface with real world systems, be it in autonomous driving or widely accessible large language models.&lt;/p&gt;</description></item><item><title>Research Assistant</title><link>https://ScalableTrustworthyAI.github.io/member/johannes/</link><pubDate>Wed, 22 May 2024 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/johannes/</guid><description>&lt;p&gt;I am currently pursuing my MSc in Machine Learning at the University of Tübingen and am a research assistant at the Scalable Trustworthy AI (STAI) group. I work on explainability, more specifically on training data attribution and concept attribution. My other interests include fairness and brain-inspired AI.&lt;/p&gt;
&lt;p&gt;I completed my BSc in Cognitive Science at the University of Tübingen in 2023. Prior to my work at STAI, I was research assistant in the Neuro-Cognitive Modeling group at the University of Tübingen and intern at FANUC Germany.&lt;/p&gt;</description></item><item><title>MSc student</title><link>https://ScalableTrustworthyAI.github.io/member/albert/</link><pubDate>Fri, 17 May 2024 13:06:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/albert/</guid><description>&lt;p&gt;I post a summary of my projects and ideas at &lt;a href="https://aldakata.github.io"&gt;aldakata.github.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am a M.Sc. Machine Learning student at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, working with Elisa Nguyen and Seong Joon Oh on &lt;a href="https://arxiv.org/abs/2303.17595"&gt;Annotation By-products&lt;/a&gt;. I am especially interested in the impact of particular training data samples on the training dynamics, with a special focus on improving data efficiency.&lt;/p&gt;
&lt;p&gt;Previously, I was a research assistant at &lt;a href="http://www.ub.edu/cvub/"&gt;CVUB&lt;/a&gt; under &lt;a href="https://scholar.google.com/citations?user=p_MCjd4AAAAJ&amp;amp;hl=en"&gt;Petia Radeva&lt;/a&gt;, where I worked on how to better model label noise on &lt;em&gt;Learning with Noisy Labels&lt;/em&gt; &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865524001132"&gt;see paper&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/anastasiia/</link><pubDate>Wed, 24 Apr 2024 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/anastasiia/</guid><description>&lt;p&gt;I am pursuing MSc degree in Data Science at the University of Tübingen, supervised by Seong Joon Oh and Elisa Nguyen. My research interests revolve around the intersection of training data attribution methods applied to large language models and fairness. Moreover, I am keen on operationalizing the EU AI Act within the industry, especially explainability and fairness requirements.&lt;/p&gt;
&lt;p&gt;I obtained my Bachelor&amp;rsquo;s degree in Political Science at Lomonosov Moscow State University and my first Master&amp;rsquo;s degree in Applied Political Analysis at Higher School of Economics in Moscow.&lt;/p&gt;</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/darina/</link><pubDate>Wed, 24 Apr 2024 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/darina/</guid><description>&lt;p&gt;I am pursuing Master&amp;rsquo;s degree in Machine Learning at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, supervised by Seong Joon Oh and Arnas Uselis.&lt;/p&gt;
&lt;p&gt;I am interested in improving the generalization capabilities of machine learning models by better understanding the underlying mechanisms that drive their performance.&lt;/p&gt;
&lt;p&gt;I received my Bachelor&amp;rsquo;s degree in Computer Science with a minor in Mathematics from &lt;a href="https://nu.edu.kz/"&gt;Nazarbayev University&lt;/a&gt; in 2022.&lt;/p&gt;</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/ankit/</link><pubDate>Fri, 01 Mar 2024 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/ankit/</guid><description>&lt;p&gt;I am a first-year PhD Student at the &lt;a href="https://tuebingen.ai/"&gt;Tübingen AI Center&lt;/a&gt;, &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, supervised by &lt;a href="https://coallaoh.github.io/"&gt;Seong Joon Oh&lt;/a&gt; and co-supervised by &lt;a href="https://bethgelab.org/"&gt;Matthias Bethge&lt;/a&gt;. My personal webpage is at &lt;a href="https://ankitsonthalia.com"&gt;ankitsonthalia.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://proceedings.neurips.cc/paper/2020/file/6cfe0e6127fa25df2a0ef2ae1067d915-Paper.pdf"&gt;simplicity bias&lt;/a&gt; often causes machine learning models to learn semantically meaningless, &amp;ldquo;spurious&amp;rdquo; correlations between inputs and outputs. This phenomenon hurts generalization, thus leading to often unpredictable failure cases and our inability to trust AI systems. I&amp;rsquo;m interested in understanding how to encourage ML models to learn more meaningful, causal correlations instead. Better generalization capability and trustworthiness would follow as direct consequences.&lt;/p&gt;</description></item><item><title>Pretrained Visual Uncertainties</title><link>https://ScalableTrustworthyAI.github.io/publication/kirchhof2024pretrained/</link><pubDate>Mon, 26 Feb 2024 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kirchhof2024pretrained/</guid><description/></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/stefano/</link><pubDate>Mon, 29 Jan 2024 19:50:20 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/stefano/</guid><description>&lt;p&gt;I am a PhD student in the International Max-Planck Research School for Intelligent Systems (&lt;a href="https://imprs.is.mpg.de/"&gt;IMPRS-IS&lt;/a&gt;), supervised by Christian Baumgartner and co-supervised by Seong Joon Oh at the University of Tübingen.&lt;/p&gt;
&lt;p&gt;I work on few-shot learning and domain generalisation for medical image analysis. I am passionate about developing more “human-like” machine learning methods, which mimic our ability to make predictions based on a limited number of training examples and to generalise to unsee tasks.&lt;/p&gt;</description></item><item><title>A Bayesian Perspective On Training Data Attribution</title><link>https://ScalableTrustworthyAI.github.io/publication/elisa2023neurips/</link><pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/elisa2023neurips/</guid><description/></item><item><title>Exploring Practitioner Perspectives On Training Data Attribution Explanations</title><link>https://ScalableTrustworthyAI.github.io/publication/elisa2023neuripsxaiw/</link><pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/elisa2023neuripsxaiw/</guid><description/></item><item><title>ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets</title><link>https://ScalableTrustworthyAI.github.io/publication/teney2023neurips/</link><pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/teney2023neurips/</guid><description/></item><item><title>URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates</title><link>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023neuripsdb/</link><pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023neuripsdb/</guid><description/></item><item><title>Neglected Free Lunch -- Learning Image Classifiers Using Annotation Byproducts</title><link>https://ScalableTrustworthyAI.github.io/publication/han2023iccv/</link><pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/han2023iccv/</guid><description/></item><item><title>Trustworthy Machine Learning</title><link>https://ScalableTrustworthyAI.github.io/publication/balint2023tml/</link><pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/balint2023tml/</guid><description/></item><item><title>Scratching Visual Transformer's Back with Uniform Attention</title><link>https://ScalableTrustworthyAI.github.io/publication/nam2023iccv/</link><pubDate>Tue, 25 Jul 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/nam2023iccv/</guid><description/></item><item><title>Arnas Uselis | PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/arnas/</link><pubDate>Mon, 24 Jul 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/arnas/</guid><description>&lt;p&gt;I&amp;rsquo;m a PhD student at the University of Tübingen and the International Max Planck Research School for Intelligent Systems (&lt;a href="https://imprs.is.mpg.de/"&gt;IMPRS-IS&lt;/a&gt;), under the supervision of Seong Joon Oh.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m primarily interested in enhancing the generalization capabilities of current machine learning systems. This involves learning robust representations from raw data and using them in a way that accurately reflects data generative processes. I believe that mimicking the structure of the real-world in our models, both in how we learn representations and in how we use them, is a key part of making progress towards trustworthy systems.&lt;/p&gt;</description></item><item><title>Probabilistic Contrastive Learning Recovers the Correct Aleatoric Uncertainty of Ambiguous Inputs</title><link>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023icml/</link><pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023icml/</guid><description/></item><item><title>URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates</title><link>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023uaieai/</link><pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023uaieai/</guid><description/></item><item><title>MSc student</title><link>https://ScalableTrustworthyAI.github.io/member/evgenii/</link><pubDate>Sat, 17 Jun 2023 13:06:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/evgenii/</guid><description>&lt;p&gt;My personal page is at &lt;a href="https://kortukov.github.io"&gt;kortukov.github.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am currently pursuing my MSc degree in Machine Learning at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, supervised by Seong Joon Oh, Elisa Nguyen and Alexander Rubinstein.
My research interests primarily revolve around mitigating the &lt;a href="https://80000hours.org/problem-profiles/artificial-intelligence/"&gt;risks associated with increasingly powerful ML systems&lt;/a&gt;.
My current focus involves exploring data-driven explainability methods and their application to language models.&lt;/p&gt;
&lt;p&gt;I receieved my Bachelor degree in Computer Science from &lt;a href="https://www.msu.ru/en/"&gt;Lomonosov Moscow State University&lt;/a&gt; in 2020. During and after my studies, I worked for about 2.5 years as a software engineer at &lt;a href="https://yandex.com/company"&gt;Yandex&lt;/a&gt;.
Prior to joining the STAI group, I had the opportunity to work as a student research assistant in the &lt;a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/decision-making/"&gt;Decision Making group&lt;/a&gt; at the University of Tübingen.&lt;/p&gt;</description></item><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/balint/</link><pubDate>Fri, 02 Jun 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/balint/</guid><description>&lt;p&gt;I am a Machine Learning MSc student at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, supervised by Seong Joon Oh, Michael Kirchhof, and Alexander Rubinstein.&lt;/p&gt;
&lt;p&gt;I am interested in model architectures capable of representing different sources of uncertainty. My goal is to contribute to the theoretical foundations of uncertainty in machine learning while developing scalable practical solutions.&lt;/p&gt;
&lt;p&gt;I received my BSc degree in Computer Science from &lt;a href="https://www.elte.hu/en/"&gt;ELTE Eötvös Loránd University&lt;/a&gt; in 2021 with the Outstanding Student of the Faculty award. I previously worked on neural program synthesis with a focus on provable correctness.&lt;/p&gt;</description></item><item><title>Collaborating PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/michael/</link><pubDate>Fri, 31 Mar 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/michael/</guid><description>&lt;p&gt;I&amp;rsquo;m a PhD student in the International Max-Planck Research School for Intelligent Systems (&lt;a href="https://imprs.is.mpg.de/"&gt;IMPRS-IS&lt;/a&gt;), co-supervised by Enkelejda Kasneci and Seong Joon Oh at the University of Tübingen.&lt;/p&gt;
&lt;p&gt;My goal is making machine learning more trustworthy by delivering pretrained uncertainty estimates along with each prediction. To this end, I&amp;rsquo;m developing &lt;a href="https://arxiv.org/abs/2207.03784"&gt;probabilistic embeddings&lt;/a&gt; that represent a model&amp;rsquo;s uncertainty directly in its embedding space. I love to understand and prove things first from a theoretical perspective first (&lt;a href="https://arxiv.org/abs/2302.02865"&gt;like MCInfoNCE&lt;/a&gt;) and then scale them to large datasets &lt;a href="https://arxiv.org/abs/2307.03810"&gt;as in the new URL benchmark&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>Postdoc Opportunity: Scalable Trustworthy AI - Novel Dataset Development</title><link>https://ScalableTrustworthyAI.github.io/opening/postdoc-mar2023/</link><pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/opening/postdoc-mar2023/</guid><description/></item><item><title>Master Projects</title><link>https://ScalableTrustworthyAI.github.io/opening/thesis/</link><pubDate>Thu, 23 Feb 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/opening/thesis/</guid><description/></item><item><title>PhD Students</title><link>https://ScalableTrustworthyAI.github.io/opening/phd/</link><pubDate>Mon, 05 Sep 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/opening/phd/</guid><description/></item><item><title>ECCV Caption: Correcting False Negatives by Collecting Machine-and-Human-verified Image-Caption Associations for MS-COCO</title><link>https://ScalableTrustworthyAI.github.io/publication/chun2022eccv/</link><pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/chun2022eccv/</guid><description/></item><item><title>Dataset Condensation via Efficient Synthetic-Data Parameterization</title><link>https://ScalableTrustworthyAI.github.io/publication/kim2022icml/</link><pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kim2022icml/</guid><description/></item><item><title>Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data</title><link>https://ScalableTrustworthyAI.github.io/publication/lee2022cvpr/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/lee2022cvpr/</guid><description/></item><item><title>Group Leader</title><link>https://ScalableTrustworthyAI.github.io/member/joon/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/joon/</guid><description>&lt;p&gt;My personal page is at &lt;a href="https://coallaoh.github.io/"&gt;seongjoonoh.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am an independent group leader at the &lt;a href="https://tuebingen.ai/"&gt;Tübingen AI Center&lt;/a&gt; at the University of Tübingen, where I lead the group on Scalable Trustworthy AI (STAI). I am interested in training reliable models (e.g. explainable, robust, and probabilistic models) and obtaining the necessary human supervision and guidance in a cost-effective way.&lt;/p&gt;
&lt;p&gt;I have been a research scientist at &lt;a href="https://github.com/naver-ai"&gt;NAVER AI Lab&lt;/a&gt; for 3.5 years. I received my PhD in computer vision and machine learning at &lt;a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning"&gt;Max-Planck Institute for Informatics&lt;/a&gt; in 2018, under the supervision of &lt;a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele"&gt;Bernt Schiele&lt;/a&gt; and &lt;a href="https://cispa.saarland/group/fritz/"&gt;Mario Fritz&lt;/a&gt;. My PhD thesis focused on the privacy and security implications of CV and ML (&lt;a href="https://publikationen.sulb.uni-saarland.de/handle/20.500.11880/27146"&gt;link&lt;/a&gt;). I received the Master of Mathematics with &lt;a href="https://en.wikipedia.org/wiki/Part_III_of_the_Mathematical_Tripos"&gt;Distinction&lt;/a&gt; in 2014 and Bachelor of Arts in Mathematics as a &lt;a href="https://en.wikipedia.org/wiki/Wrangler_(University_of_Cambridge)"&gt;Wrangler&lt;/a&gt; in 2013, both from the University of Cambridge.&lt;/p&gt;</description></item><item><title>MSc student</title><link>https://ScalableTrustworthyAI.github.io/member/luca/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/luca/</guid><description>&lt;p&gt;Hey there!&lt;/p&gt;
&lt;p&gt;My current work involves a master&amp;rsquo;s thesis on Uncertainty Quantification in Large Language Models, conducted at the Scalable Trustworthy AI Chair (Prof. Seong Joon Oh) in collaboration with Apple (Dr. Michael Kirchhof). Holding a background in classical computer science, I have specialized in Machine Learning and Artificial Intelligence during my masters.&lt;/p&gt;
&lt;p&gt;While the recent progress in LLM research and tools is significant, solving fundamental challenges such as uncertainty (regarding output reliability) and explainability (understanding system rationale) remain critical in making these systems beneficial in a wide area of application scenarios. My thesis research is dedicated to contributing to the resolution of these issues.&lt;/p&gt;</description></item><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/fabian/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/fabian/</guid><description>&lt;p&gt;I am pursuing my MSc in Machine Learning at the University of Tübingen. Currently, I am working on a research project about the loss landscape of CLIP models during fine-tuning, supervised by Ankit Sonthalia, Arnas Uselis and Seong Joon Oh. I am interested in parameter spaces, particularly in how connecting multiple models in the parameter space can improve in- and out-of-distribution generalization.&lt;/p&gt;
&lt;p&gt;Before coming to Tübingen, I received my BSc in Computer Science from the Karlsruhe Institute of Technology (KIT). I was a research assistant at the Fraunhofer Institute, working on anomaly detection with Variational Autoencoders. Currently, I am also a research assistant at the &lt;a href="https://www.math.uni-tuebingen.de/en/research-chairs/info-methods/mathematical-methods-in-computer-science?set_language=en"&gt;Mathematical Methods in Computer Science&lt;/a&gt; group, working on merging neural networks.&lt;/p&gt;</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/alex/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/alex/</guid><description>&lt;p&gt;My personal page is at &lt;a href="https://arubique.github.io/"&gt;arubique.github.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am a PhD Student at the &lt;a href="https://tuebingen.ai/"&gt;Tübingen AI Center&lt;/a&gt; at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt; and the International Max Planck Research School for Intelligent Systems (&lt;a href="https://imprs.is.mpg.de/"&gt;IMPRS-IS&lt;/a&gt;), where I work in the group on Scalable Trustworthy AI (STAI). I am interested in researching the ways of making models not only perfectly classify MNIST but also not fail too much on real world tasks. In case possibilities of some models are limited to academic datasets, I want to understand why that is the case.&lt;/p&gt;</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/elif/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/elif/</guid><description>&lt;p&gt;I am a first year PhD student in the Scalable Trustworthy AI (STAI) group at the &lt;a href="https://tuebingen.ai/"&gt;Tübingen AI Center&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I received my Master’s degree in Computer Science from University of Tübingen in 2022, and Bachelor’s in Computer Science from &lt;a href="https://www.uni-saarland.de/"&gt;Saarland University&lt;/a&gt; in 2019. I am interested in understanding abstractions humans and neural networks perform in visual representations and how to use these to improve model robustness and Human-Computer Interaction.&lt;/p&gt;</description></item><item><title>Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective</title><link>https://ScalableTrustworthyAI.github.io/publication/scimeca2022iclr/</link><pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/scimeca2022iclr/</guid><description/></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/elisa/</link><pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/elisa/</guid><description>&lt;p&gt;My personal page is at &lt;a href="https://elisanguyen.github.io"&gt;elisanguyen.github.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am a PhD student at the University of Tübingen and the International Max Planck Research School for Intelligent Systems (&lt;a href="https://imprs.is.mpg.de/"&gt;IMPRS-IS&lt;/a&gt;). My research focus is on exploring training data attribution as a means of helping humans understand model behavior.&lt;/p&gt;
&lt;p&gt;I absolved my Master’s in &lt;a href="https://www.utwente.nl/en/education/master/programmes/interaction-technology/"&gt;Interaction Technology at the University of Twente&lt;/a&gt; and my Bachelor’s in &lt;a href="https://www.nordakademie.de/duales-studium/wirtschaftsinformatik"&gt;Computer Science and Management at the Nordakademie&lt;/a&gt;. I did my Bachelor studies in a &lt;a href="https://www.daad.de/en/study-and-research-in-germany/plan-your-studies/dual-study-programmes/"&gt;dual study format&lt;/a&gt; in cooperation with Airbus, where I also worked for about 2.5 years as an IT project manager for CAD software in waterfall and agile projects.&lt;/p&gt;</description></item><item><title>Markdown ipsum</title><link>https://ScalableTrustworthyAI.github.io/post/post1/</link><pubDate>Tue, 12 Jul 2016 15:50:58 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/post/post1/</guid><description>&lt;h1 id="magorum-notissima-limite-sua-pars-simus-sumptis"&gt;Magorum notissima limite sua pars simus sumptis&lt;/h1&gt;
&lt;h2 id="incessit-ignota-coniunx-serpunt"&gt;Incessit ignota coniunx serpunt&lt;/h2&gt;
&lt;p&gt;Lorem markdownum ab cunas, semine commissus matrona manibusque plumis, nova sub
Spartana &lt;em&gt;loca ignibus&lt;/em&gt;. In partibus muneris, paludes rara, plectrumque, fontis,
concubitus a locoque demptos exclamat conde ab aethera &lt;strong&gt;nihil&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Quamquam abit vulnere nec intus decidit clamor&lt;/li&gt;
&lt;li&gt;Nocuit quae tamen timent aperta&lt;/li&gt;
&lt;li&gt;Cervice preces totumque postquam nunc iacit sive&lt;/li&gt;
&lt;li&gt;Potestas te sis putaret sceleri totiens&lt;/li&gt;
&lt;li&gt;Retro profundo ad sede Iovem in este&lt;/li&gt;
&lt;li&gt;In ait flumina intrare Troiae&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ut fatis &lt;em&gt;praecordia alvum iamque&lt;/em&gt;, adeo tympana &lt;strong&gt;male&lt;/strong&gt; silvas. Dammis adit
sanguine tamen lacrimis tu venias ut si gratum! &lt;a href="http://www.traxere-veniat.org/"&gt;Nigrior
et&lt;/a&gt; saepe cum iterum cura it generosque animam
raptusque in possunt ut portat, Latreus Iason tenuit macies in. Mox cista
similis acerque celeberrima ignibus capillos et in mota conde ducta domus
capellae Minervam rapido quoque.&lt;/p&gt;</description></item><item><title/><link>https://ScalableTrustworthyAI.github.io/overview/overview/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/overview/overview/</guid><description>&lt;p&gt;AI has left the lab. It is reshaping how we live and work. To fully exploit its benefits, we must address critical gaps in trustworthiness. We work on &lt;strong&gt;Deploying General AI in the Private World&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI’s transformative era&lt;/strong&gt;. AI offers potential to address global challenges. It can increase productivity, support ageing populations, and tackle urgent issues like climate change. Since the introduction of ChatGPT, AI has left the lab. It is now used by billions worldwide and is shaping the economy and society. AI is no longer experimental; it is a real force driving change.&lt;/p&gt;</description></item><item><title>Trustworthy Machine Learning</title><link>https://ScalableTrustworthyAI.github.io/courses/tml_winter_2223/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/courses/tml_winter_2223/</guid><description>&lt;h2 id="overview"&gt;Overview&lt;/h2&gt;
&lt;h3 id="goal"&gt;Goal&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Students will be able to critically read, assess, and discuss research work in Trustworthy Machine Learning (TML).&lt;/li&gt;
&lt;li&gt;Students will gain the technical background to implement basic TML techniques in a deep learning framework.&lt;/li&gt;
&lt;li&gt;Students will be ready to conduct their own research in TML and make contributions to the research community.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="prerequisites"&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Familiarity with Python and PyTorch coding.&lt;/li&gt;
&lt;li&gt;A pass grade from the Deep Learning Course (or equivalent).&lt;/li&gt;
&lt;li&gt;Basic knowledge of machine learning concepts.&lt;/li&gt;
&lt;li&gt;Basic maths: multivariate calculus, linear algebra, probability, statistics, and optimisation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="reading-list"&gt;Reading list&lt;/h3&gt;
&lt;p&gt;Recommended papers from each topic.&lt;/p&gt;</description></item><item><title>Trustworthy Machine Learning</title><link>https://ScalableTrustworthyAI.github.io/courses/tml_winter_2324/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/courses/tml_winter_2324/</guid><description>&lt;h2 id="overview"&gt;Overview&lt;/h2&gt;
&lt;h3 id="goal"&gt;Goal&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Students will be able to critically read, assess, and discuss research work in Trustworthy Machine Learning (TML).&lt;/li&gt;
&lt;li&gt;Students will gain the technical background to implement basic TML techniques in a deep learning framework.&lt;/li&gt;
&lt;li&gt;Students will be ready to conduct their own research in TML and make contributions to the research community.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="prerequisites"&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Familiarity with Python and PyTorch coding.&lt;/li&gt;
&lt;li&gt;A pass grade from the Deep Learning Course (or equivalent).&lt;/li&gt;
&lt;li&gt;Basic knowledge of machine learning concepts.&lt;/li&gt;
&lt;li&gt;Basic maths: multivariate calculus, linear algebra, probability, statistics, and optimisation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="tml-book"&gt;TML Book&lt;/h2&gt;
&lt;p&gt;Last year&amp;rsquo;s course materials are now a book. You can find it here: &lt;a href="https://trustworthyml.io/"&gt;https://trustworthyml.io/&lt;/a&gt;. It&amp;rsquo;s also on arXiv: &lt;a href="https://arxiv.org/abs/2310.08215"&gt;https://arxiv.org/abs/2310.08215&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>Trustworthy Machine Learning</title><link>https://ScalableTrustworthyAI.github.io/courses/tml_winter_2425/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/courses/tml_winter_2425/</guid><description>&lt;h2 id="overview"&gt;Overview&lt;/h2&gt;
&lt;h3 id="goal"&gt;Goal&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Students will be able to critically read, assess, and discuss research work in Trustworthy Machine Learning (TML).&lt;/li&gt;
&lt;li&gt;Students will gain the technical background to implement basic TML techniques in a deep learning framework.&lt;/li&gt;
&lt;li&gt;Students will be ready to conduct their own research in TML and make contributions to the research community.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="prerequisites"&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Familiarity with Python and PyTorch coding.&lt;/li&gt;
&lt;li&gt;A pass grade from the Deep Learning Course (or equivalent).&lt;/li&gt;
&lt;li&gt;Basic knowledge of machine learning concepts.&lt;/li&gt;
&lt;li&gt;Basic maths: multivariate calculus, linear algebra, probability, statistics, and optimisation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="tml-book"&gt;TML Book&lt;/h2&gt;
&lt;p&gt;Last year&amp;rsquo;s course materials are now a book. You can find it here: &lt;a href="https://trustworthyml.io/"&gt;https://trustworthyml.io/&lt;/a&gt;. It&amp;rsquo;s also on arXiv: &lt;a href="https://arxiv.org/abs/2310.08215"&gt;https://arxiv.org/abs/2310.08215&lt;/a&gt;.&lt;/p&gt;</description></item></channel></rss>