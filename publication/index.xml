<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Publications on Scalable Trustworthy AI</title><link>https://ScalableTrustworthyAI.github.io/publication/</link><description>Recent content in Publications on Scalable Trustworthy AI</description><generator>Hugo</generator><language>en</language><copyright>&amp;copy; Seong Joon Oh, 2024</copyright><lastBuildDate>Sun, 02 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://ScalableTrustworthyAI.github.io/publication/index.xml" rel="self" type="application/rss+xml"/><item><title>Do Deep Neural Network Solutions Form a Star Domain?</title><link>https://ScalableTrustworthyAI.github.io/publication/ankit2024star/</link><pubDate>Sun, 02 Feb 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/ankit2024star/</guid><description/></item><item><title>Intermediate Layer Classifiers for OOD Generalization</title><link>https://ScalableTrustworthyAI.github.io/publication/arnas2025iclr/</link><pubDate>Sun, 02 Feb 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/arnas2025iclr/</guid><description/></item><item><title>Decoupled Finetuning for Domain Generalizable Semantic Segmentation</title><link>https://ScalableTrustworthyAI.github.io/publication/jaehyun2025iclr/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/jaehyun2025iclr/</guid><description/></item><item><title>Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks</title><link>https://ScalableTrustworthyAI.github.io/publication/balint2024disentanglement/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/balint2024disentanglement/</guid><description/></item><item><title>Towards User-Focused Research in Training Data Attribution for Human-Centered Explainable AI</title><link>https://ScalableTrustworthyAI.github.io/publication/elisa2024needs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/elisa2024needs/</guid><description/></item><item><title>Scalable Ensemble Diversification for OOD Generalization and Detection</title><link>https://ScalableTrustworthyAI.github.io/publication/alex2024diversify/</link><pubDate>Wed, 25 Sep 2024 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/alex2024diversify/</guid><description/></item><item><title>Studying Large Language Model Behaviors Under Realistic Knowledge Conflicts</title><link>https://ScalableTrustworthyAI.github.io/publication/evgenii2024ralm/</link><pubDate>Wed, 24 Apr 2024 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/evgenii2024ralm/</guid><description/></item><item><title>Pretrained Visual Uncertainties</title><link>https://ScalableTrustworthyAI.github.io/publication/kirchhof2024pretrained/</link><pubDate>Mon, 26 Feb 2024 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kirchhof2024pretrained/</guid><description/></item><item><title>A Bayesian Perspective On Training Data Attribution</title><link>https://ScalableTrustworthyAI.github.io/publication/elisa2023neurips/</link><pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/elisa2023neurips/</guid><description/></item><item><title>Exploring Practitioner Perspectives On Training Data Attribution Explanations</title><link>https://ScalableTrustworthyAI.github.io/publication/elisa2023neuripsxaiw/</link><pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/elisa2023neuripsxaiw/</guid><description/></item><item><title>ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets</title><link>https://ScalableTrustworthyAI.github.io/publication/teney2023neurips/</link><pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/teney2023neurips/</guid><description/></item><item><title>URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates</title><link>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023neuripsdb/</link><pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023neuripsdb/</guid><description/></item><item><title>Neglected Free Lunch -- Learning Image Classifiers Using Annotation Byproducts</title><link>https://ScalableTrustworthyAI.github.io/publication/han2023iccv/</link><pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/han2023iccv/</guid><description/></item><item><title>Trustworthy Machine Learning</title><link>https://ScalableTrustworthyAI.github.io/publication/balint2023tml/</link><pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/balint2023tml/</guid><description/></item><item><title>Scratching Visual Transformer's Back with Uniform Attention</title><link>https://ScalableTrustworthyAI.github.io/publication/nam2023iccv/</link><pubDate>Tue, 25 Jul 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/nam2023iccv/</guid><description/></item><item><title>Probabilistic Contrastive Learning Recovers the Correct Aleatoric Uncertainty of Ambiguous Inputs</title><link>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023icml/</link><pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023icml/</guid><description/></item><item><title>URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates</title><link>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023uaieai/</link><pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kirchhof2023uaieai/</guid><description/></item><item><title>Playing repeated games with Large Language Models</title><link>https://ScalableTrustworthyAI.github.io/publication/elif2023arxiv/</link><pubDate>Wed, 31 May 2023 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/elif2023arxiv/</guid><description/></item><item><title>ECCV Caption: Correcting False Negatives by Collecting Machine-and-Human-verified Image-Caption Associations for MS-COCO</title><link>https://ScalableTrustworthyAI.github.io/publication/chun2022eccv/</link><pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/chun2022eccv/</guid><description/></item><item><title>Dataset Condensation via Efficient Synthetic-Data Parameterization</title><link>https://ScalableTrustworthyAI.github.io/publication/kim2022icml/</link><pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/kim2022icml/</guid><description/></item><item><title>Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data</title><link>https://ScalableTrustworthyAI.github.io/publication/lee2022cvpr/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/lee2022cvpr/</guid><description/></item><item><title>Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective</title><link>https://ScalableTrustworthyAI.github.io/publication/scimeca2022iclr/</link><pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate><guid>https://ScalableTrustworthyAI.github.io/publication/scimeca2022iclr/</guid><description/></item></channel></rss>