<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Members on Scalable Trustworthy AI</title><link>https://ScalableTrustworthyAI.github.io/member/</link><description>Recent content in Members on Scalable Trustworthy AI</description><generator>Hugo</generator><language>en</language><copyright>&amp;copy; Seong Joon Oh, 2024</copyright><lastBuildDate>Fri, 09 May 2025 17:17:22 +0200</lastBuildDate><atom:link href="https://ScalableTrustworthyAI.github.io/member/index.xml" rel="self" type="application/rss+xml"/><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/bora/</link><pubDate>Fri, 09 May 2025 17:17:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/bora/</guid><description>&lt;p&gt;I am currently pursuing a Master’s degree in Machine Learning at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, where I am conducting my thesis research under the supervision of Seong Joon Oh and Arnas Uselis.&lt;/p&gt;
&lt;p&gt;My research interests lie in enhancing the generalization abilities of multimodal machine learning models and gaining deeper insight into when, why, and how they fail. I believe that studying model representations is key to understanding the underlying factors that drive model performance—both successes and failures.&lt;/p&gt;</description></item><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/philipp/</link><pubDate>Thu, 08 May 2025 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/philipp/</guid><description>&lt;p&gt;I am a MSc student at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, supervised by Seong Joon Oh, Elisa Nguyen, and Ameya Prabhu (Bethgelab Tübingen). My thesis aims to quantify the influence of training data samples on LLM-generated text. I am especially interested in how attribution results differ between base models and instruction-tuned models.&lt;/p&gt;
&lt;p&gt;I earned my Bachelor’s degree with distinction in &lt;a href="https://www.uni-goettingen.de/en/640713.html"&gt;Mathematical Data Science at the Georg-August University in Göttingen&lt;/a&gt;, where I wrote my thesis in cooperation with AUDI AG. There, I explored Active Learning to reduce labeling costs in Surface Defect Detection for Automobiles.&lt;/p&gt;</description></item><item><title>Collaborating PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/lennart/</link><pubDate>Thu, 15 Aug 2024 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/lennart/</guid><description>&lt;p&gt;I am a PhD student, co-supervised by &lt;a href="https://cogsys.reutlingen-university.de/about-us/members/cristobal-curio/?L=1"&gt;Cristòbal Curio&lt;/a&gt; at Reutlingen University and &lt;a href="https://coallaoh.github.io/"&gt;Seong Joon Oh&lt;/a&gt; at the University of Tübingen. My personal page is at &lt;a href="https://lennartbramlage.com"&gt;lennartbramlage.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A broader interest in decision making under uncertainty has informed my current focus on rapid and accurate uncertainty estimation in deep neural networks. I believe that the quantification and source-attribution of their failures is indispensable wherever these models interface with real world systems, be it in autonomous driving or widely accessible large language models.&lt;/p&gt;</description></item><item><title>Research Assistant</title><link>https://ScalableTrustworthyAI.github.io/member/johannes/</link><pubDate>Wed, 22 May 2024 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/johannes/</guid><description>&lt;p&gt;I am currently pursuing my MSc in Machine Learning at the University of Tübingen and am a research assistant at the Scalable Trustworthy AI (STAI) group. I work on explainability, more specifically on training data attribution and concept attribution. My other interests include fairness and brain-inspired AI.&lt;/p&gt;
&lt;p&gt;I completed my BSc in Cognitive Science at the University of Tübingen in 2023. Prior to my work at STAI, I was research assistant in the Neuro-Cognitive Modeling group at the University of Tübingen and intern at FANUC Germany.&lt;/p&gt;</description></item><item><title>MSc student</title><link>https://ScalableTrustworthyAI.github.io/member/albert/</link><pubDate>Fri, 17 May 2024 13:06:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/albert/</guid><description>&lt;p&gt;I post a summary of my projects and ideas at &lt;a href="https://aldakata.github.io"&gt;aldakata.github.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am a M.Sc. Machine Learning student at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, working with Elisa Nguyen and Seong Joon Oh on &lt;a href="https://arxiv.org/abs/2303.17595"&gt;Annotation By-products&lt;/a&gt;. I am especially interested in the impact of particular training data samples on the training dynamics, with a special focus on improving data efficiency.&lt;/p&gt;
&lt;p&gt;Previously, I was a research assistant at &lt;a href="http://www.ub.edu/cvub/"&gt;CVUB&lt;/a&gt; under &lt;a href="https://scholar.google.com/citations?user=p_MCjd4AAAAJ&amp;amp;hl=en"&gt;Petia Radeva&lt;/a&gt;, where I worked on how to better model label noise on &lt;em&gt;Learning with Noisy Labels&lt;/em&gt; &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865524001132"&gt;see paper&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/anastasiia/</link><pubDate>Wed, 24 Apr 2024 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/anastasiia/</guid><description>&lt;p&gt;I am pursuing MSc degree in Data Science at the University of Tübingen, supervised by Seong Joon Oh and Elisa Nguyen. My research interests revolve around the intersection of training data attribution methods applied to large language models and fairness. Moreover, I am keen on operationalizing the EU AI Act within the industry, especially explainability and fairness requirements.&lt;/p&gt;
&lt;p&gt;I obtained my Bachelor&amp;rsquo;s degree in Political Science at Lomonosov Moscow State University and my first Master&amp;rsquo;s degree in Applied Political Analysis at Higher School of Economics in Moscow.&lt;/p&gt;</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/darina/</link><pubDate>Wed, 24 Apr 2024 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/darina/</guid><description>&lt;p&gt;I am pursuing Master&amp;rsquo;s degree in Machine Learning at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, supervised by Seong Joon Oh and Arnas Uselis.&lt;/p&gt;
&lt;p&gt;I am interested in improving the generalization capabilities of machine learning models by better understanding the underlying mechanisms that drive their performance.&lt;/p&gt;
&lt;p&gt;I received my Bachelor&amp;rsquo;s degree in Computer Science with a minor in Mathematics from &lt;a href="https://nu.edu.kz/"&gt;Nazarbayev University&lt;/a&gt; in 2022.&lt;/p&gt;</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/ankit/</link><pubDate>Fri, 01 Mar 2024 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/ankit/</guid><description>&lt;p&gt;I am a first-year PhD Student at the &lt;a href="https://tuebingen.ai/"&gt;Tübingen AI Center&lt;/a&gt;, &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, supervised by &lt;a href="https://coallaoh.github.io/"&gt;Seong Joon Oh&lt;/a&gt; and co-supervised by &lt;a href="https://bethgelab.org/"&gt;Matthias Bethge&lt;/a&gt;. My personal webpage is at &lt;a href="https://ankitsonthalia.com"&gt;ankitsonthalia.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://proceedings.neurips.cc/paper/2020/file/6cfe0e6127fa25df2a0ef2ae1067d915-Paper.pdf"&gt;simplicity bias&lt;/a&gt; often causes machine learning models to learn semantically meaningless, &amp;ldquo;spurious&amp;rdquo; correlations between inputs and outputs. This phenomenon hurts generalization, thus leading to often unpredictable failure cases and our inability to trust AI systems. I&amp;rsquo;m interested in understanding how to encourage ML models to learn more meaningful, causal correlations instead. Better generalization capability and trustworthiness would follow as direct consequences.&lt;/p&gt;</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/stefano/</link><pubDate>Mon, 29 Jan 2024 19:50:20 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/stefano/</guid><description>&lt;p&gt;I am a PhD student in the International Max-Planck Research School for Intelligent Systems (&lt;a href="https://imprs.is.mpg.de/"&gt;IMPRS-IS&lt;/a&gt;), supervised by Christian Baumgartner and co-supervised by Seong Joon Oh at the University of Tübingen.&lt;/p&gt;
&lt;p&gt;I work on few-shot learning and domain generalisation for medical image analysis. I am passionate about developing more “human-like” machine learning methods, which mimic our ability to make predictions based on a limited number of training examples and to generalise to unsee tasks.&lt;/p&gt;</description></item><item><title>Arnas Uselis | PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/arnas/</link><pubDate>Mon, 24 Jul 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/arnas/</guid><description>&lt;p&gt;I&amp;rsquo;m a PhD student at the University of Tübingen and the International Max Planck Research School for Intelligent Systems (&lt;a href="https://imprs.is.mpg.de/"&gt;IMPRS-IS&lt;/a&gt;), under the supervision of Seong Joon Oh.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m primarily interested in enhancing the generalization capabilities of current machine learning systems. This involves learning robust representations from raw data and using them in a way that accurately reflects data generative processes. I believe that mimicking the structure of the real-world in our models, both in how we learn representations and in how we use them, is a key part of making progress towards trustworthy systems.&lt;/p&gt;</description></item><item><title>MSc student</title><link>https://ScalableTrustworthyAI.github.io/member/evgenii/</link><pubDate>Sat, 17 Jun 2023 13:06:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/evgenii/</guid><description>&lt;p&gt;My personal page is at &lt;a href="https://kortukov.github.io"&gt;kortukov.github.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am currently pursuing my MSc degree in Machine Learning at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, supervised by Seong Joon Oh, Elisa Nguyen and Alexander Rubinstein.
My research interests primarily revolve around mitigating the &lt;a href="https://80000hours.org/problem-profiles/artificial-intelligence/"&gt;risks associated with increasingly powerful ML systems&lt;/a&gt;.
My current focus involves exploring data-driven explainability methods and their application to language models.&lt;/p&gt;
&lt;p&gt;I receieved my Bachelor degree in Computer Science from &lt;a href="https://www.msu.ru/en/"&gt;Lomonosov Moscow State University&lt;/a&gt; in 2020. During and after my studies, I worked for about 2.5 years as a software engineer at &lt;a href="https://yandex.com/company"&gt;Yandex&lt;/a&gt;.
Prior to joining the STAI group, I had the opportunity to work as a student research assistant in the &lt;a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/decision-making/"&gt;Decision Making group&lt;/a&gt; at the University of Tübingen.&lt;/p&gt;</description></item><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/balint/</link><pubDate>Fri, 02 Jun 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/balint/</guid><description>&lt;p&gt;I am a Machine Learning MSc student at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt;, supervised by Seong Joon Oh, Michael Kirchhof, and Alexander Rubinstein.&lt;/p&gt;
&lt;p&gt;I am interested in model architectures capable of representing different sources of uncertainty. My goal is to contribute to the theoretical foundations of uncertainty in machine learning while developing scalable practical solutions.&lt;/p&gt;
&lt;p&gt;I received my BSc degree in Computer Science from &lt;a href="https://www.elte.hu/en/"&gt;ELTE Eötvös Loránd University&lt;/a&gt; in 2021 with the Outstanding Student of the Faculty award. I previously worked on neural program synthesis with a focus on provable correctness.&lt;/p&gt;</description></item><item><title>Collaborating PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/michael/</link><pubDate>Fri, 31 Mar 2023 11:26:00 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/michael/</guid><description>&lt;p&gt;I&amp;rsquo;m a PhD student in the International Max-Planck Research School for Intelligent Systems (&lt;a href="https://imprs.is.mpg.de/"&gt;IMPRS-IS&lt;/a&gt;), co-supervised by Enkelejda Kasneci and Seong Joon Oh at the University of Tübingen.&lt;/p&gt;
&lt;p&gt;My goal is making machine learning more trustworthy by delivering pretrained uncertainty estimates along with each prediction. To this end, I&amp;rsquo;m developing &lt;a href="https://arxiv.org/abs/2207.03784"&gt;probabilistic embeddings&lt;/a&gt; that represent a model&amp;rsquo;s uncertainty directly in its embedding space. I love to understand and prove things first from a theoretical perspective first (&lt;a href="https://arxiv.org/abs/2302.02865"&gt;like MCInfoNCE&lt;/a&gt;) and then scale them to large datasets &lt;a href="https://arxiv.org/abs/2307.03810"&gt;as in the new URL benchmark&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>Group Leader</title><link>https://ScalableTrustworthyAI.github.io/member/joon/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/joon/</guid><description>&lt;p&gt;My personal page is at &lt;a href="https://coallaoh.github.io/"&gt;seongjoonoh.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am an independent group leader at the &lt;a href="https://tuebingen.ai/"&gt;Tübingen AI Center&lt;/a&gt; at the University of Tübingen, where I lead the group on Scalable Trustworthy AI (STAI). I am interested in training reliable models (e.g. explainable, robust, and probabilistic models) and obtaining the necessary human supervision and guidance in a cost-effective way.&lt;/p&gt;
&lt;p&gt;I have been a research scientist at &lt;a href="https://github.com/naver-ai"&gt;NAVER AI Lab&lt;/a&gt; for 3.5 years. I received my PhD in computer vision and machine learning at &lt;a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning"&gt;Max-Planck Institute for Informatics&lt;/a&gt; in 2018, under the supervision of &lt;a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele"&gt;Bernt Schiele&lt;/a&gt; and &lt;a href="https://cispa.saarland/group/fritz/"&gt;Mario Fritz&lt;/a&gt;. My PhD thesis focused on the privacy and security implications of CV and ML (&lt;a href="https://publikationen.sulb.uni-saarland.de/handle/20.500.11880/27146"&gt;link&lt;/a&gt;). I received the Master of Mathematics with &lt;a href="https://en.wikipedia.org/wiki/Part_III_of_the_Mathematical_Tripos"&gt;Distinction&lt;/a&gt; in 2014 and Bachelor of Arts in Mathematics as a &lt;a href="https://en.wikipedia.org/wiki/Wrangler_(University_of_Cambridge)"&gt;Wrangler&lt;/a&gt; in 2013, both from the University of Cambridge.&lt;/p&gt;</description></item><item><title>MSc student</title><link>https://ScalableTrustworthyAI.github.io/member/luca/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/luca/</guid><description>&lt;p&gt;Hey there!&lt;/p&gt;
&lt;p&gt;My current work involves a master&amp;rsquo;s thesis on Uncertainty Quantification in Large Language Models, conducted at the Scalable Trustworthy AI Chair (Prof. Seong Joon Oh) in collaboration with Apple (Dr. Michael Kirchhof). Holding a background in classical computer science, I have specialized in Machine Learning and Artificial Intelligence during my masters.&lt;/p&gt;
&lt;p&gt;While the recent progress in LLM research and tools is significant, solving fundamental challenges such as uncertainty (regarding output reliability) and explainability (understanding system rationale) remain critical in making these systems beneficial in a wide area of application scenarios. My thesis research is dedicated to contributing to the resolution of these issues.&lt;/p&gt;</description></item><item><title>MSc Student</title><link>https://ScalableTrustworthyAI.github.io/member/fabian/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/fabian/</guid><description>&lt;p&gt;I am pursuing my MSc in Machine Learning at the University of Tübingen. Currently, I am working on a research project about the loss landscape of CLIP models during fine-tuning, supervised by Ankit Sonthalia, Arnas Uselis and Seong Joon Oh. I am interested in parameter spaces, particularly in how connecting multiple models in the parameter space can improve in- and out-of-distribution generalization.&lt;/p&gt;
&lt;p&gt;Before coming to Tübingen, I received my BSc in Computer Science from the Karlsruhe Institute of Technology (KIT). I was a research assistant at the Fraunhofer Institute, working on anomaly detection with Variational Autoencoders. Currently, I am also a research assistant at the &lt;a href="https://www.math.uni-tuebingen.de/en/research-chairs/info-methods/mathematical-methods-in-computer-science?set_language=en"&gt;Mathematical Methods in Computer Science&lt;/a&gt; group, working on merging neural networks.&lt;/p&gt;</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/alex/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/alex/</guid><description>&lt;p&gt;My personal page is at &lt;a href="https://arubique.github.io/"&gt;arubique.github.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am a PhD Student at the &lt;a href="https://tuebingen.ai/"&gt;Tübingen AI Center&lt;/a&gt; at the &lt;a href="https://uni-tuebingen.de/en/"&gt;University of Tübingen&lt;/a&gt; and the International Max Planck Research School for Intelligent Systems (&lt;a href="https://imprs.is.mpg.de/"&gt;IMPRS-IS&lt;/a&gt;), where I work in the group on Scalable Trustworthy AI (STAI). I am interested in researching the ways of making models not only perfectly classify MNIST but also not fail too much on real world tasks. In case possibilities of some models are limited to academic datasets, I want to understand why that is the case.&lt;/p&gt;</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/elif/</link><pubDate>Tue, 24 May 2022 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/elif/</guid><description>&lt;p&gt;I am a first year PhD student in the Scalable Trustworthy AI (STAI) group at the &lt;a href="https://tuebingen.ai/"&gt;Tübingen AI Center&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I received my Master’s degree in Computer Science from University of Tübingen in 2022, and Bachelor’s in Computer Science from &lt;a href="https://www.uni-saarland.de/"&gt;Saarland University&lt;/a&gt; in 2019. I am interested in understanding abstractions humans and neural networks perform in visual representations and how to use these to improve model robustness and Human-Computer Interaction.&lt;/p&gt;</description></item><item><title>PhD Student</title><link>https://ScalableTrustworthyAI.github.io/member/elisa/</link><pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate><guid>https://ScalableTrustworthyAI.github.io/member/elisa/</guid><description>&lt;p&gt;My personal page is at &lt;a href="https://elisanguyen.github.io"&gt;elisanguyen.github.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am a PhD student at the University of Tübingen and the International Max Planck Research School for Intelligent Systems (&lt;a href="https://imprs.is.mpg.de/"&gt;IMPRS-IS&lt;/a&gt;). My research focus is on exploring training data attribution as a means of helping humans understand model behavior.&lt;/p&gt;
&lt;p&gt;I absolved my Master’s in &lt;a href="https://www.utwente.nl/en/education/master/programmes/interaction-technology/"&gt;Interaction Technology at the University of Twente&lt;/a&gt; and my Bachelor’s in &lt;a href="https://www.nordakademie.de/duales-studium/wirtschaftsinformatik"&gt;Computer Science and Management at the Nordakademie&lt;/a&gt;. I did my Bachelor studies in a &lt;a href="https://www.daad.de/en/study-and-research-in-germany/plan-your-studies/dual-study-programmes/"&gt;dual study format&lt;/a&gt; in cooperation with Airbus, where I also worked for about 2.5 years as an IT project manager for CAD software in waterfall and agile projects.&lt;/p&gt;</description></item></channel></rss>